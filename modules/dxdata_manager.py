import requests
import json
import os
import copy
from datetime import datetime
from modules.config_loader import MAIMAI_VERSION, DXDATA_VERSION_FILE

def merge_json(source, target):
    """é€’å½’åˆå¹¶ä¸¤ä¸ª JSON ç»“æ„ï¼ˆdict / list / åŸºç¡€ç±»å‹ï¼‰"""
    # dict åˆå¹¶é€»è¾‘
    if isinstance(source, dict) and isinstance(target, dict):
        for key, value in source.items():
            if key not in target:
                target[key] = copy.deepcopy(value)
            else:
                src_val, tgt_val = value, target[key]

                # å­—ç¬¦ä¸²äº’è¡¥é€»è¾‘
                if isinstance(src_val, str) and isinstance(tgt_val, str):
                    if src_val and not tgt_val:
                        target[key] = src_val
                    # è‹¥ target éç©ºåˆ™ä¿ç•™ï¼Œä¸åŠ¨
                    continue

                # åˆ—è¡¨é€»è¾‘
                elif isinstance(src_val, list) and isinstance(tgt_val, list):
                    if not tgt_val and src_val:
                        target[key] = copy.deepcopy(src_val)
                    elif tgt_val and not src_val:
                        continue
                    else:
                        for i in range(min(len(src_val), len(tgt_val))):
                            merge_json(src_val[i], tgt_val[i])
                        # å¦‚æœ source æ¯” target é•¿ï¼Œè¿½åŠ å‰©ä½™éƒ¨åˆ†
                        if len(src_val) > len(tgt_val):
                            target[key].extend(copy.deepcopy(src_val[len(tgt_val):]))

                # é€’å½’åˆå¹¶ dict
                elif isinstance(src_val, dict) and isinstance(tgt_val, dict):
                    merge_json(src_val, tgt_val)

                # ç±»å‹ä¸ä¸€è‡´æ—¶ä»¥éç©ºå€¼ä¸ºå‡†
                else:
                    if tgt_val in (None, '', [], {}):
                        target[key] = copy.deepcopy(src_val)

    # list åˆå¹¶é€»è¾‘ï¼ˆé¡¶å±‚ï¼‰
    elif isinstance(source, list) and isinstance(target, list):
        if not target and source:
            target.extend(copy.deepcopy(source))
        elif target and not source:
            return target
        else:
            for i in range(min(len(source), len(target))):
                merge_json(source[i], target[i])
            if len(source) > len(target):
                target.extend(copy.deepcopy(source[len(target):]))

    # å…¶ä»–ç±»å‹äº’è¡¥
    else:
        if target in (None, '', [], {}):
            target = copy.deepcopy(source)

    return target


def merge_json_by_key(source, target, key_field):
    """
    æŒ‰ key_field åŒ¹é…å¹¶åˆå¹¶ source ä¸ targetã€‚
    é€‚ç”¨äºé¡¶å±‚ç»“æ„ç±»ä¼¼ {"songs": [ {...}, {...} ]}
    """
    result = copy.deepcopy(target)

    for k, v in source.items():
        if isinstance(v, list) and all(isinstance(i, dict) for i in v):
            # å¤„ç†åˆ—è¡¨ä¸­çš„å­—å…¸ï¼ˆå¸¦ key_fieldï¼‰
            target_list = result.get(k, [])
            target_index = {item.get(key_field): item for item in target_list if key_field in item}

            for item in v:
                key_val = item.get(key_field)
                if key_val in target_index:
                    merge_json(item, target_index[key_val])
                else:
                    target_list.append(copy.deepcopy(item))
            result[k] = target_list

        elif isinstance(v, dict):
            # é€’å½’åˆå¹¶ dict
            if k in result and isinstance(result[k], dict):
                merge_json(v, result[k])
            else:
                result[k] = copy.deepcopy(v)

        else:
            # ç®€å•ç±»å‹ï¼šä»…åœ¨ç›®æ ‡ä¸ºç©ºæ—¶æ›´æ–°
            if k not in result or result[k] in (None, '', [], {}):
                result[k] = copy.deepcopy(v)

    return result

def merge_songs_list(source_songs, target_songs, key_field="title"):
    """
    åˆå¹¶ä¸¤ä¸ª songs åˆ—è¡¨,æŒ‰ key_field å»é‡

    Args:
        source_songs: æºæ­Œæ›²åˆ—è¡¨
        target_songs: ç›®æ ‡æ­Œæ›²åˆ—è¡¨
        key_field: ç”¨äºåŒ¹é…çš„é”®å

    Returns:
        åˆå¹¶åçš„æ­Œæ›²åˆ—è¡¨
    """
    result = copy.deepcopy(target_songs)
    target_index = {item.get(key_field): item for item in result if key_field in item}

    for item in source_songs:
        key_val = item.get(key_field)
        if key_val in target_index:
            # å¦‚æœå·²å­˜åœ¨,åˆå¹¶æ•°æ®
            merge_json(item, target_index[key_val])
        else:
            # å¦‚æœä¸å­˜åœ¨,æ·»åŠ æ–°é¡¹
            result.append(copy.deepcopy(item))

    return result

def load_dxdata(url):
    try:
        response = requests.get(url)
        response.raise_for_status()

        data = response.json()

        data['songs'] = _split_song_sheets_by_type(data['songs'])
        for song in data['songs']:
            for version in data['versions']:
                if version['version'] == song['version']:
                    for sheet in song.get("sheets", []):
                        if 'count' not in version:
                            version['count'] = 0
                        if sheet['regions']['jp']:
                            version['count'] += 1

        return data

    except requests.RequestException as e:
        return None
    except json.JSONDecodeError as e:
        return None

def _split_song_sheets_by_type(song_list):
    result = []

    for song in song_list:
        base_info = {
            "category": song["category"],
            "title": song["title"],
            "artist": song["artist"],
            "bpm": song["bpm"],
            "version": song.get("version", ""),
            "cover_url": f"https://dp4p6x0xfi5o9.cloudfront.net/maimai/img/cover/{song['imageName']}.png",
            "cover_name": f"{song['imageName']}",
            "search_acronyms": song.get("searchAcronyms", [])
        }

        sheets_by_type = {"dx": [], "std": [], "utage": []}
        version_by_type = {}

        for sheet in song.get("sheets", []):
            sheet_type = sheet.get("type")
            if "multiverInternalLevelValue" in sheet:
                sheet["internalLevelValue"] = sheet["multiverInternalLevelValue"].get(MAIMAI_VERSION["jp"][-1], sheet["internalLevelValue"])

            if sheet_type in sheets_by_type:
                new_sheet = sheet.copy()
                version_by_type[sheet_type] = new_sheet.pop("version", base_info["version"])
                new_sheet.pop("type", None)
                sheets_by_type[sheet_type].append(new_sheet)

        for sheet_type, sheets in sheets_by_type.items():
            if sheets:
                entry = base_info.copy()
                entry["type"] = sheet_type
                entry["version"] = version_by_type.get(sheet_type, base_info["version"])
                entry["sheets"] = sheets
                result.append(entry)

    return result


def get_dxdata_stats(data):
    """
    è·å– dxdata çš„ç»Ÿè®¡ä¿¡æ¯

    Args:
        data: dxdata JSON æ•°æ®

    Returns:
        dict: åŒ…å«æ­Œæ›²æ•°ã€è°±é¢æ•°ç­‰ç»Ÿè®¡ä¿¡æ¯
    """
    if not data or 'songs' not in data:
        return None

    total_songs = len(data['songs'])
    total_sheets = 0

    for song in data['songs']:
        if 'sheets' in song:
            total_sheets += len(song['sheets'])

    return {
        'total_songs': total_songs,
        'total_sheets': total_sheets,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }


def load_dxdata_version_history():
    """åŠ è½½ dxdata ç‰ˆæœ¬å†å²"""
    if not os.path.exists(DXDATA_VERSION_FILE):
        return None

    try:
        with open(DXDATA_VERSION_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return None


def save_dxdata_version_history(stats):
    """ä¿å­˜ dxdata ç‰ˆæœ¬å†å²"""
    try:
        # ç¡®ä¿ data ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(DXDATA_VERSION_FILE), exist_ok=True)

        with open(DXDATA_VERSION_FILE, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False


def update_dxdata_with_comparison(urls, save_to: str = None):
    """
    æ›´æ–° dxdata å¹¶è¿”å›ä¸ä¸Šæ¬¡çš„å¯¹æ¯”ä¿¡æ¯

    Args:
        url: dxdata API URL
        save_to: ä¿å­˜æ–‡ä»¶è·¯å¾„

    Returns:
        dict: åŒ…å«æ›´æ–°ç»“æœå’Œå¯¹æ¯”ä¿¡æ¯
            {
                'success': bool,
                'new_stats': dict,
                'old_stats': dict,
                'diff': {
                    'songs_added': int,
                    'sheets_added': int
                },
                'message': str
            }
    """
    # åŠ è½½æ—§ç‰ˆæœ¬ä¿¡æ¯
    old_version = load_dxdata_version_history()

    # åŠ è½½æ–°æ•°æ®
    new_datas = []
    for url in urls:
        new_datas.append(load_dxdata(url))

    # åªåˆå¹¶ songs å­—æ®µ
    for i in range(1, len(new_datas)):
        new_datas[0]['songs'] = merge_songs_list(new_datas[i]['songs'], new_datas[0]['songs'], "title")

    new_data = new_datas[0]

    if not new_data:
        return {
            'success': False,
            'message': 'âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ï¼'
        }


    if save_to:
        with open(save_to, "w", encoding="utf-8") as file:
            json.dump(new_data, file, ensure_ascii=False, indent=2)

    # è·å–æ–°æ•°æ®ç»Ÿè®¡
    new_stats = get_dxdata_stats(new_data)

    if not new_stats:
        return {
            'success': False,
            'message': 'âŒ ãƒ‡ãƒ¼ã‚¿è§£æå¤±æ•—ï¼'
        }

    # ä¿å­˜æ–°ç‰ˆæœ¬ä¿¡æ¯
    save_dxdata_version_history(new_stats)

    # è®¡ç®—å·®å¼‚
    if old_version:
        songs_diff = new_stats['total_songs'] - old_version['total_songs']
        sheets_diff = new_stats['total_sheets'] - old_version['total_sheets']

        # æ„å»ºæ¶ˆæ¯
        message_parts = ['âœ… Dxdata Updated!', '']

        if songs_diff > 0:
            message_parts.append(f'ğŸµ æ–°æ›²: +{songs_diff}é¦–')
        elif songs_diff < 0:
            message_parts.append(f'ğŸµ æ¥½æ›²: {songs_diff}é¦–')
        else:
            message_parts.append('ğŸµ æ–°æ›²: ãªã—')

        if sheets_diff > 0:
            message_parts.append(f'ğŸ“Š æ–°è­œé¢: +{sheets_diff}å€‹')
        elif sheets_diff < 0:
            message_parts.append(f'ğŸ“Š è­œé¢: {sheets_diff}å€‹')
        else:
            message_parts.append('ğŸ“Š æ–°è­œé¢: ãªã—')

        message_parts.append('')
        message_parts.append(f'ğŸ“… å‰å›æ›´æ–°: {old_version["timestamp"]}')
        message_parts.append(f'ğŸ“ˆ ç¾åœ¨: æ¥½æ›²{new_stats["total_songs"]}é¦– / è­œé¢{new_stats["total_sheets"]}å€‹')

        return {
            'success': True,
            'new_stats': new_stats,
            'old_stats': old_version,
            'diff': {
                'songs_added': songs_diff,
                'sheets_added': sheets_diff
            },
            'message': '\n'.join(message_parts)
        }
    else:
        # ç¬¬ä¸€æ¬¡æ›´æ–°
        message_parts = [
            'âœ… Dxdata Updated!',
            '',
            f'ğŸ“ˆ æ¥½æ›²: {new_stats["total_songs"]}é¦–',
            f'ğŸ“Š è­œé¢: {new_stats["total_sheets"]}å€‹',
            '',
            '(åˆå›æ›´æ–°å®Œäº†ï¼)'
        ]

        return {
            'success': True,
            'new_stats': new_stats,
            'old_stats': None,
            'diff': None,
            'message': '\n'.join(message_parts)
        }
